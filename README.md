# ğŸ¤– LLM Sentiment Analysis: BERT Fine-Tuning

## ğŸ¯ Project Goal
This project demonstrates the ability to effectively fine-tune a pre-trained Large Language Model (LLM) of the Encoder type (BERT-based) to solve a classic NLP challenge: binary sentiment classification on movie reviews.

## âš™ï¸ Technologies and Architecture
* **Architecture:** BERT / DistilBERT (Encoder-Only Model)
* **Key Libraries:** Hugging Face `transformers`, `datasets`, PyTorch, Scikit-learn
* **Dataset:** IMDB Movie Reviews (50,000 film reviews)
* **Goal:** Achieve high F1-score and Accuracy on the test set.

## ğŸ“Š Results (Post Fine-tuning)
| Metric | Value |
| :--- | :--- |
| **Test Accuracy** | TBD |
| **Test F1-score** | TBD |
| **Confusion Matrix** | TBD (Image/Visualization) |

## ğŸš€ Repository Structure
/notebooks         # Jupyter Notebooks containing EDA and the full Fine-tuning process.
/models            # Saved best model weights and tokenizer configurations.
/requirements.txt  # List of Python dependencies.
/README.md         # Project description, methodology, and results.

## ğŸ› ï¸ Setup and Execution
(Instructions to be added once the code is finalized.)
